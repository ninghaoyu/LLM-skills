# AWS Well-Architected Framework 检查清单

本文档包含 WAF 六大支柱的详细检查清单，以及 AI/ML 和大数据项目的特殊检查项。

## 目录

1. [WAF 六大支柱](#waf-六大支柱)
2. [AI/ML 特有检查](#aiml-特有检查)
3. [大数据特有检查](#大数据特有检查)

---

## WAF 六大支柱

### 1️⃣ 卓越运营 (Operational Excellence)

**核心问题**:
- [ ] 是否定义了运维流程和标准?
- [ ] 是否使用 IaC (Infrastructure as Code)?
- [ ] 是否配置了自动化运维工具?
- [ ] 是否建立了变更管理流程?
- [ ] 是否建立了完整的监控与可观测性体系?
- [ ] 是否配置了关键业务指标(KPI)监控?
- [ ] 是否有自动化的告警和响应机制?

**检查点**:

#### 日志聚合与管理
- **集中式日志存储**: CloudWatch Logs / S3 / Splunk
- **日志保留期**:
  - 应用日志: 30-90 天
  - 审计日志: 1-3 年 (合规要求)
  - 错误日志: 永久保留 (用于事后分析)
- **日志采样与过滤**:
  - 避免日志爆炸,配置合理的采样率
  - 敏感信息脱敏 (不记录密钥、Token 等)
  - 日志级别管理 (生产环境避免 DEBUG 级别过多)
- **日志聚合工具**:
  - CloudWatch Insights 用于快速查询
  - Athena + S3 用于长期分析
  - 第三方: Splunk、ELK、DataDog 等

#### 监控与告警
- **关键指标监控**:
  - **系统级**: CPU、内存、磁盘、网络 I/O
  - **应用级**: 错误率、延迟、吞吐量、并发数
  - **业务级**: DAU、转化率、成功率、用户反馈
  - **成本级**: 按服务成本、预测成本、异常成本

- **告警策略**:
  - [ ] 是否定义了告警阈值和级别 (Critical/High/Medium/Low)?
  - [ ] 是否配置了多种通知渠道 (邮件、Slack、SMS、电话)?
  - [ ] 是否实施了告警聚合 (避免告警风暴)?
  - [ ] 是否配置了告警升级机制 (无响应时自动升级)?
  - [ ] 是否有告警页面 (On-Call 轮换)?

- **告警示例**:
  | 指标 | 阈值 | 级别 | 通知 |
  |-----|------|------|------|
  | 错误率 | > 5% | Critical | 立即告警 + 升级 |
  | P99 延迟 | > 5s | High | Slack + 邮件 |
  | CPU 使用率 | > 80% | Medium | 邮件 |
  | 磁盘使用率 | > 90% | High | Slack + 邮件 |

#### 分布式追踪与性能诊断
- **追踪工具**: AWS X-Ray / OpenTelemetry / Jaeger
- **关键配置**:
  - [ ] 是否启用了分布式追踪?
  - [ ] 是否追踪了跨服务调用?
  - [ ] 是否记录了关键业务事件?
  - [ ] 追踪保留期是否合理 (通常 7-30 天)?

#### 仪表盘与可视化
- **仪表盘类型**:
  - 运维监控仪表盘: 系统健康、告警状态、关键指标
  - 业务仪表盘: KPI、收入、用户行为
  - 成本仪表盘: 各服务成本、预测趋势、异常项
  - 性能仪表盘: 延迟分布、错误分布、容量使用
- **更新频率**: 实时 (关键指标) 或 1-5 分钟 (普通指标)
- **访问权限**: 基于角色的仪表盘可见性

#### 自动化运维
- **基础设施运维**:
  - 自动化补丁管理 (Systems Manager Patch Manager)
  - 自动化配置管理 (Systems Manager State Manager)
  - 自动化修复 (EventBridge + Lambda)

- **应用运维**:
  - CI/CD 流程自动化
  - 自动化健康检查和故障转移
  - 自动化扩缩容 (Auto Scaling)
  - 自动化日志清理和备份

#### 变更管理与回滚
- [ ] 是否有变更审批流程?
- [ ] 是否支持快速回滚 (< 5 分钟)?
- [ ] 是否有灰度发布能力 (金丝雀、蓝绿)?
- [ ] 是否记录所有变更 (CloudTrail)?

#### 成本监控
- **成本监控工具**:
  - AWS Cost Explorer: 历史成本分析
  - AWS Budgets: 成本预算和告警
  - AWS Cost Anomaly Detection: 异常成本检测
  - 第三方: CloudHealth、Densify 等

- **成本监控要点**:
  - [ ] 是否设置了月度/季度预算?
  - [ ] 是否配置了成本异常告警?
  - [ ] 是否按 Tag 追踪成本?
  - [ ] 是否定期审查和优化成本 (月度/季度)?

**最佳实践**:
- 所有基础设施使用 IaC 定义,版本控制
- 集中式日志聚合,定期审查日志
- 建立关键指标基线,定期对标分析
- 实施自动化告警和响应,减少人工干预
- 定期进行演练 (月度),验证监控和告警的有效性
- 实施 On-Call 轮换,保证 24/7 支持
- 定期进行成本审查,优化资源配置

---

### 2️⃣ 安全性 (Security)

**核心问题**:
- [ ] 是否遵循最小权限原则 (IAM)?
- [ ] 是否启用静态数据加密?
- [ ] 是否启用传输加密 (TLS)?
- [ ] 是否配置网络隔离 (VPC/Security Group)?
- [ ] 是否启用审计日志 (CloudTrail)?

**检查点**:
- **IAM 角色**: 禁止使用 Root 账户，使用细粒度权限
- **KMS 加密**: S3、RDS、EBS 静态加密
- **WAF 防护**: 公网暴露的应用
- **MFA**: 管理员账户强制 MFA
- **VPC Flow Logs**: 网络流量审计
- **CloudTrail**: 所有 API 调用审计

**最佳实践**:
- 默认拒绝，显式允许
- 定期轮换密钥和凭证
- 使用 AWS Secrets Manager 管理敏感信息

---

### 3️⃣ 可靠性 (Reliability)

**核心问题**:
- [ ] 是否实现 Multi-AZ 部署?
- [ ] 是否配置自动故障转移?
- [ ] 是否定义了 RTO/RPO?
- [ ] 是否配置了备份策略?
- [ ] 是否进行了容量规划?

**检查点**:
- **Multi-AZ**: RDS Multi-AZ / Aurora Replicas
- **Auto Scaling**: 动态调整容量
- **备份策略**: AWS Backup / Snapshot
- **健康检查**: Route 53 / ALB
- **RTO/RPO**: 明确恢复目标

**最佳实践**:
- 生产环境必须 Multi-AZ
- 定期测试灾备流程
- 监控关键指标并设置告警

---

### 4️⃣ 性能效率 (Performance Efficiency)

**核心问题**:
- [ ] 是否选择了适合工作负载的实例类型?
- [ ] 是否使用了缓存机制?
- [ ] 是否启用了 CDN (若适用)?
- [ ] 是否优化了数据库查询?

**检查点**:
- **实例类型**: 计算优化 / 内存优化 / 通用
- **缓存**: ElastiCache / DAX
- **CDN**: CloudFront
- **性能洞察**: RDS Performance Insights

**实例类型选择**:
| 工作负载 | 推荐实例 | 说明 |
|---------|---------|-----|
| Web 应用 | t3, m5 | 通用型 |
| 计算密集 | c5, c6i | 高 CPU |
| 内存密集 | r5, r6i | 高内存 |
| 机器学习 | p3, g4dn | GPU |

**最佳实践**:
- 使用缓存减少数据库负载
- 启用 CloudFront 减少延迟
- 定期审查和优化资源配置

---

### 5️⃣ 成本优化 (Cost Optimization)

**核心问题**:
- [ ] 是否使用了 Auto Scaling 避免资源浪费?
- [ ] 是否考虑了 Reserved Instance / Savings Plans?
- [ ] 是否配置了 S3 生命周期策略?
- [ ] 是否启用了成本监控 (Cost Explorer)?

**检查点**:
- **Auto Scaling**: 按需扩展
- **S3 Lifecycle**: Standard → IA → Glacier
- **Spot Instances**: 非关键工作负载
- **Cost Explorer**: 成本分析
- **Budgets**: 成本告警

**成本优化策略**:
1. **计算**:
   - RI / Savings Plans (1年/3年承诺)
   - Spot Instances (最高 90% 折扣)
   - Auto Scaling (避免过度配置)

2. **存储**:
   - S3 Intelligent-Tiering
   - 删除未使用的快照和卷
   - 压缩和去重

3. **网络**:
   - 使用 VPC Endpoints 减少数据传输费
   - CloudFront 缓存减少回源

**最佳实践**:
- 定期审查资源使用情况
- 删除未使用的资源
- 使用 Cost Anomaly Detection

---

### 6️⃣ 可持续性 (Sustainability)

**核心问题**:
- [ ] 是否选择了能效更高的实例类型 (Graviton)?
- [ ] 是否优化了资源利用率?
- [ ] 是否选择了绿色能源的 Region?

**检查点**:
- **Graviton 实例**: ARM 架构，能效更高
- **Serverless**: 按需计费，无闲置资源
- **自动关闭**: 开发/测试环境非工作时间关闭

**Graviton 实例优势**:
- 性能提升 40%
- 价格降低 20%
- 能耗降低 60%

**最佳实践**:
- 优先使用 Serverless 服务
- 开发环境使用 Lambda / Fargate
- 选择可再生能源比例高的 Region

---

## AI/ML 特有检查

### 🤖 AI Cost Optimization

**Token 成本控制**:
- [ ] 是否设置单次请求 Token 上限?
- [ ] 是否使用 Prompt 缓存减少重复调用?
- [ ] 是否根据任务选择合适的模型?

**推理成本优化**:
- [ ] SageMaker Endpoint 是否使用 Auto Scaling?
- [ ] 是否考虑 Serverless Inference (不定期流量)?
- [ ] 训练是否使用 Spot Instances?

**向量数据库成本**:
- [ ] 是否选择 OpenSearch Serverless 而非常驻集群?
- [ ] 是否配置 Index 生命周期策略?

**成本对比**:
| 模型 | Input Token 成本 | Output Token 成本 | 适用场景 |
|-----|-----------------|-------------------|---------|
| Claude 3.5 Sonnet | $0.003/1K | $0.015/1K | 复杂推理 |
| Claude 3.5 Haiku | $0.0008/1K | $0.0016/1K | 简单任务 |
| Llama 3.1 70B | $0.00065/1K | $0.00065/1K | 成本敏感 |
| Titan Text | $0.0002/1K | $0.0006/1K | 低成本 |

---

### 🤖 AI Performance

**推理延迟**:
- [ ] 是否满足业务 SLA (如 <500ms)?
- [ ] 是否使用缓存 (Redis) 减少重复推理?
- [ ] 是否配置 Provisioned Throughput (高并发)?

**模型选择**:
- [ ] 模型大小是否匹配任务复杂度 (避免大材小用)?
- [ ] 是否测试过多个模型的性能/成本比?

**批处理优化**:
- [ ] 批量推理是否使用 Batch Transform?
- [ ] 是否合并多个请求减少 API 调用?

---

### 🤖 AI Security

**数据隐私**:
- [ ] 训练数据是否加密存储 (S3 + KMS)?
- [ ] 是否使用 VPC Endpoints 避免公网传输?
- [ ] Bedrock 是否选择不记录数据的模型?

**Prompt Injection 防护**:
- [ ] 是否对用户输入进行过滤和验证?
- [ ] 是否限制 System Prompt 不被覆盖?

**模型访问控制**:
- [ ] 是否使用 IAM 细粒度控制模型调用权限?
- [ ] 是否启用 CloudTrail 审计 API 调用?

**Prompt Injection 防护示例**:
```python
def validate_input(user_input):
    # 检查危险关键词
    dangerous_keywords = ["ignore previous", "system prompt", "override"]
    if any(keyword in user_input.lower() for keyword in dangerous_keywords):
        return False, "输入包含不安全内容"

    # 长度限制
    if len(user_input) > 4000:
        return False, "输入过长"

    return True, "输入安全"
```

---

### 🤖 AI Reliability

**降级策略**:
- [ ] 当主模型不可用时，是否有备用模型?
- [ ] 是否设置超时和重试机制?

**幻觉检测**:
- [ ] 是否对 LLM 输出进行验证 (如 Guardrails)?
- [ ] 是否结合 RAG 提供事实依据?

**版本管理**:
- [ ] 模型是否版本化 (SageMaker Model Registry)?
- [ ] 是否支持 A/B 测试和回滚?

---

### 🤖 MLOps (AI/ML 特有的运维与监控)

**监控与可观测性**:
- [ ] 是否监控模型性能指标 (准确率、延迟、成本)?
- [ ] 是否配置 SageMaker Model Monitor (数据漂移检测)?
- [ ] 是否记录 Prompt/Response 用于调试?

**AI/ML 特有的监控指标**:

#### LLM 推理监控
| 指标 | 说明 | 告警阈值 | 频率 |
|-----|------|---------|------|
| **Token 使用量** | 实际消耗的输入/输出 Token 数 | 接近配额 80% | 实时 |
| **推理延迟** | 平均/P50/P95/P99 推理时间 | P99 > 1s | 5 分钟 |
| **成功率** | 推理成功 / 总请求数 | < 95% | 5 分钟 |
| **幻觉率** | 检测到幻觉的请求占比 | > 5% | 小时级 |
| **模型异常** | API 错误、超时、限流 | 任何 | 实时 |
| **成本趋势** | 日度/周度/月度 Token 成本 | 环比增长 > 20% | 日度 |

#### 知识库与向量数据库监控 (如适用)
| 指标 | 说明 | 告警阈值 | 频率 |
|-----|------|---------|------|
| **检索延迟** | 向量数据库查询时间 | > 500ms | 5 分钟 |
| **检索准确率** | 返回的相关文档占比 | < 80% | 小时级 |
| **存储使用率** | 向量数据库容量使用 | > 85% | 小时级 |
| **数据新鲜度** | 向量数据的最后更新时间 | > 24h | 日度 |
| **同步失败率** | 文档到向量的同步失败 | > 0% | 实时 |

#### 系统级监控
| 指标 | 说明 | 告警阈值 | 频率 |
|-----|------|---------|------|
| **计算资源利用率** | GPU/CPU/内存使用率 | > 85% | 5 分钟 |
| **并发限制命中** | 触发并发限制的请求数 | > 0 | 实时 |
| **API 配额使用** | 已使用配额百分比 | > 80% | 实时 |
| **错误日志** | 应用错误、异常堆栈 | 关键错误立即 | 实时 |

#### 业务级监控 (AI Agentic 特有)
| 指标 | 说明 | 告警阈值 | 频率 |
|-----|------|---------|------|
| **Agent 成功率** | 任务完成成功 / 总任务数 | < 90% | 5 分钟 |
| **人工审核占比** | 需要人工审核的比例 | > 20% | 小时级 |
| **平均工具调用数** | 完成任务的平均工具调用次数 | 无固定阈值,用于趋势分析 | 小时级 |
| **用户满意度** | 用户反馈评分 | < 3/5 | 日度 |

**日志与追踪**:
- [ ] 是否记录了完整的 Prompt 和 Completion (用于调试)?
  - 注意: 生产环境应脱敏敏感信息
- [ ] 是否追踪了每个请求的完整生命周期?
  - 从输入 → 模型选择 → Token 使用 → 输出
- [ ] 是否记录了工具调用链路?
  - 调用了哪些工具、参数、返回值、耗时
- [ ] 是否记录了错误和异常?
  - 模型错误、工具失败、超时、限流等

**监控实现**:
- CloudWatch Logs: 应用日志聚合
- CloudWatch Metrics: 自定义指标发送
- X-Ray: 分布式追踪,特别是 Agent 工具调用链
- 第三方 LLM 监控: Langfuse、LLM Observability 平台

**持续优化**:
- [ ] 是否建立模型重训练流程?
- [ ] 是否收集用户反馈优化 Prompt?
- [ ] 是否定期分析日志,识别改进机会?
  - 常见错误类型
  - 长尾延迟问题
  - Token 浪费现象
- [ ] 是否进行 A/B 测试,比较模型/Prompt 的效果?
  - 新模型 vs 旧模型
  - 新 Prompt vs 旧 Prompt
  - 不同工具链的效果

---

## 大数据特有检查

### 📊 Big Data Cost

**存储成本**:
- [ ] S3 是否配置生命周期策略 (Standard → IA → Glacier)?
- [ ] 是否使用 S3 Intelligent-Tiering 自动优化?
- [ ] 是否删除/归档过期数据?

**计算成本**:
- [ ] EMR 是否使用临时集群 (用后即删)?
- [ ] 是否使用 Spot Instances (非关键任务)?
- [ ] Redshift 是否使用 Reserved Instances / Serverless?

**数据传输成本**:
- [ ] 是否使用 VPC Endpoints 避免公网流量费?
- [ ] 跨 Region 复制是否必要?

**成本优化策略**:
- EMR 临时集群 vs 常驻集群: 节省 70%+
- Spot Instances: 最高 90% 折扣
- Redshift Serverless: 按查询计费，避免闲置成本

---

### 📊 Big Data Performance

**查询性能**:
- [ ] S3 数据是否合理分区 (按日期/地区)?
- [ ] 是否使用列式存储 (Parquet/ORC)?
- [ ] Athena 查询是否优化 (避免 SELECT *)?

**数据处理性能**:
- [ ] EMR 实例类型是否适配工作负载 (计算 vs 内存)?
- [ ] Glue Job 是否配置合理的 DPU 数量?
- [ ] Kinesis Shard 数量是否满足吞吐量?

**并发控制**:
- [ ] Redshift 并发扩展是否启用?
- [ ] Athena 查询是否限制并发数?

**查询优化示例**:
```sql
-- ❌ 差的查询 (全表扫描)
SELECT * FROM logs WHERE date = '2024-01-15';

-- ✅ 好的查询 (分区过滤)
SELECT user_id, event_type, timestamp
FROM logs
WHERE year='2024' AND month='01' AND day='15';
```

---

### 📊 Big Data Reliability

**数据一致性**:
- [ ] 是否处理重复数据 (去重逻辑)?
- [ ] 流处理是否支持 Exactly-Once 语义?

**容错机制**:
- [ ] EMR 是否配置自动恢复?
- [ ] Glue Job 是否支持 Bookmark (断点续传)?
- [ ] 是否配置死信队列 (DLQ)?

**数据质量**:
- [ ] 是否配置 Glue Data Quality 检查?
- [ ] 是否验证数据 Schema?

---

### 📊 Big Data Security

**数据加密**:
- [ ] S3 是否启用服务端加密 (SSE-S3/SSE-KMS)?
- [ ] Redshift 是否启用加密?
- [ ] Kinesis 是否启用传输加密?

**访问控制**:
- [ ] 是否使用 Lake Formation 细粒度权限?
- [ ] 是否遵循最小权限原则 (IAM)?
- [ ] 是否启用 S3 Bucket Policy 限制访问?

**数据脱敏**:
- [ ] 敏感数据是否脱敏处理?
- [ ] 是否使用 Glue DataBrew 进行数据清洗?

---

### 📊 Data Governance (大数据特有的运维与监控)

**数据管道监控与告警**:

#### ETL/流处理监控
| 指标 | 说明 | 告警阈值 | 频率 |
|-----|------|---------|------|
| **Job 成功率** | 成功完成的 Job / 总 Job 数 | < 95% | 每次执行后 |
| **Job 执行时间** | 实际执行时间 vs 预期时间 | 超出预期 > 50% | 每次执行后 |
| **Job 失败原因** | 数据错误、资源不足、超时等 | 关键失败立即 | 实时 |
| **数据延迟** | 数据进入 vs 处理完毕的时间差 | > SLA | 实时 |
| **数据丢失** | 进入系统的数据是否完整到达 | > 0 | 实时 |
| **数据重复** | 重复处理的数据占比 | > 0% (精确一次) | 实时 |

#### 流处理 (Kinesis/Kafka) 监控
| 指标 | 说明 | 告警阈值 | 频率 |
|-----|------|---------|------|
| **消费延迟 (Consumer Lag)** | 消费者vs生产者的位置差 | > 5 分钟 | 1 分钟 |
| **吞吐量** | 每秒处理的记录数 | < 预期 20% | 1 分钟 |
| **异常消息** | 无法解析的消息占比 | > 0% | 实时 |
| **死信队列积压** | DLQ 中的消息数 | > 0 | 实时 |
| **处理延迟 (End-to-End)** | 从进入流到完全处理的时间 | > SLA | 1 分钟 |

#### 数据仓库与分析监控
| 指标 | 说明 | 告警阈值 | 频率 |
|-----|------|---------|------|
| **查询性能** | 平均/P95 查询执行时间 | P95 > 预期值 2 倍 | 1 小时 |
| **并发查询数** | 同时执行的查询数 | > 系统限制 | 1 分钟 |
| **数据更新延迟** | 新数据多久后可被查询 | > SLA | 实时 |
| **磁盘扫描量** | 每个查询扫描的数据量 | > 预期 3 倍 | 1 小时 |
| **热点分区** | 是否存在数据倾斜 | 分区数据差异 > 5 倍 | 日度 |

#### 数据湖和存储监控
| 指标 | 说明 | 告警阈值 | 频率 |
|-----|------|---------|------|
| **存储使用量** | 已用容量 vs 总容量 | > 85% | 日度 |
| **数据增长率** | 日度/周度增长速度 | 异常增长 | 日度 |
| **S3 成本** | 按存储类别的成本 | 月度环比增长 > 20% | 日度 |
| **分区完整性** | 缺失的数据分区占比 | > 0% | 日度 |
| **文件碎片化** | 小文件 (< 128MB) 占比 | > 30% | 周度 |

**数据质量监控**:
- [ ] 是否配置了自动数据质量检查?
  - 完整性检查 (NULL 值、缺失字段)
  - 准确性检查 (数值范围、格式验证)
  - 一致性检查 (主键重复、外键约束)
  - 及时性检查 (数据新鲜度)
- [ ] 是否有数据异常告警?
  - 统计值异常 (均值/中位数偏离基线)
  - 关键维度异常 (某个维度的值缺失或异常增长)
  - 数据漂移检测 (Schema 变化、新字段出现)

**数据治理**:
- [ ] 是否建立数据目录 (Glue Catalog / Hive Metastore)?
  - 所有表都有清晰的元数据定义
  - 有数据所有者和主要联系人
  - 文档说明数据用途和敏感等级
- [ ] 是否定义数据保留策略?
  - 不同敏感等级的数据保留期不同
  - 自动化清理过期数据
  - 合规性要求 (GDPR、等保等)
- [ ] 是否记录数据血缘关系?
  - 数据从源头到最终用途的全链路
  - 支持影响分析 (修改A会影响B)
  - 审计跟踪 (谁访问了什么数据)

**自动化运维**:
- [ ] ETL 是否使用调度工具?
  - AWS Step Functions / MWAA (Airflow) / Glue Workflows
  - 支持依赖管理 (A 完成后运行 B)
  - 失败重试和通知
  - 可视化工作流监控
- [ ] 是否自动化数据质量检查?
  - Glue Data Quality / Great Expectations
  - 检查失败时自动告警
  - 支持阻塞后续流程
- [ ] 是否自动化数据清理?
  - 自动删除过期分区
  - 自动清理临时文件
  - 自动压缩小文件
- [ ] 是否自动化成本优化?
  - 自动转移数据到低成本存储 (IA / Glacier)
  - 自动调整 EMR/Redshift 资源
  - 定期优化查询性能

**监控实现**:
- CloudWatch Metrics: 自定义指标发送 (ETL 状态、数据量等)
- AWS Glue Data Catalog: 元数据和血缘追踪
- EventBridge: ETL 失败告警和自动响应
- CloudWatch Logs Insights: 日志查询和分析
- 第三方数据治理: Apache Atlas、AWS Lake Formation
